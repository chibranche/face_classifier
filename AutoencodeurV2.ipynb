{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Input, Conv2DTranspose, Reshape, Activation \n",
    "from keras.layers import UpSampling2D, Lambda, concatenate, LeakyReLU\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Activation\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définit le path vers les différents folders utiles\n",
    "\n",
    "def path_var(dest):\n",
    "    global images_path, WEIGHTS_FOLDER,DATA_FOLDER\n",
    "    if dest=='local':\n",
    "        images_path = './IMDB/imdb_crop/'   #Dataset IMDB\n",
    "        WEIGHTS_FOLDER = './ae_weights/'       #Poids de l'autoencodeur déjà entraîné\n",
    "        DATA_FOLDER = images_path\n",
    "        \n",
    "    if dest =='hydra':\n",
    "        images_path = '/donnees/jmorin/imdb_crop/'\n",
    "        WEIGHTS_FOLDER = '/donnees/jmorin/weights/'\n",
    "        DATA_FOLDER = images_path\n",
    "\n",
    "dest='local'\n",
    "#dest='hydra'\n",
    "\n",
    "path_var(dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images : 0\n"
     ]
    }
   ],
   "source": [
    "#Load images filenames\n",
    "from glob import glob\n",
    "\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "NUM_IMAGES = len(filenames)\n",
    "print(\"Total number of images : \" + str(NUM_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: './IMDB/imdb_crop/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6ef0576ca441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                     \u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'input'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                                                     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                                       )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         )\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: './IMDB/imdb_crop/'"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = (64,64,3) # Image dimension\n",
    "BATCH_SIZE = 512\n",
    "#Z_DIM = 64 # Dimension of the latent vector (z)\n",
    "Z_DIM =  512 # Dimension of the latent vector (z)\n",
    "\n",
    "dataset = ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
    "\n",
    "data_flow_train= dataset.flow_from_directory(DATA_FOLDER,target_size = INPUT_DIM[:2],\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode = 'input',\n",
    "                                                    subset = 'training',\n",
    "                                      )\n",
    "\n",
    "data_flow_val= dataset.flow_from_directory(DATA_FOLDER,target_size = INPUT_DIM[:2],\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode = 'input',\n",
    "                                                    subset = 'validation',\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "face_score_treshold = 3\n",
    "\n",
    "# load mat file\n",
    "dataset = loadmat(images_path + 'imdb.mat')\n",
    "\n",
    "# extract info \n",
    "image_names_array = dataset['imdb']['full_path'][0, 0][0]\n",
    "dob_array = dataset['imdb']['dob'][0, 0][0]  # dob = date of birth\n",
    "photo_date_array = dataset['imdb']['photo_taken'][0, 0][0]\n",
    "gender_classes = dataset['imdb']['gender'][0, 0][0]\n",
    "celeb_id_array = dataset['imdb']['celeb_id'][0, 0][0]\n",
    "\n",
    "# create mask \n",
    "face_score = dataset['imdb']['face_score'][0, 0][0]\n",
    "second_face_score = dataset['imdb']['second_face_score'][0, 0][0]\n",
    "face_score_mask = face_score > face_score_treshold\n",
    "second_face_score_mask = np.isnan(second_face_score)\n",
    "unknown_dob_mask = np.logical_not(np.logical_or(np.isnan(dob_array), np.isnan(photo_date_array)))\n",
    "mask = np.logical_and(face_score_mask, second_face_score_mask)\n",
    "mask = np.logical_and(mask, unknown_dob_mask)\n",
    "\n",
    "# apply mask\n",
    "image_names_array = image_names_array[mask]\n",
    "dob_array = dob_array[mask]\n",
    "photo_date_array = photo_date_array[mask]\n",
    "gender_classes = gender_classes[mask]\n",
    "celeb_id_array = celeb_id_array[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image_names_array.shape, image_names_array[0])\n",
    "# print(dob_array.shape, dob_array[0])\n",
    "# print(photo_date_array.shape, photo_date_array[0])\n",
    "# print(gender_classes.shape, gender_classes[0])\n",
    "# print(celeb_id_array.shape, celeb_id_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'image_names': [ el[0] for el in image_names_array],\n",
    "                        'dob': dob_array,\n",
    "                        'photo_date': photo_date_array,\n",
    "                        'gender_classes': gender_classes,\n",
    "                        'celeb_id': celeb_id_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age_in_year(dob, photo_date):  \n",
    "    dob = date.fromordinal(dob)\n",
    "    photo_date = date(year=photo_date,\n",
    "                      month=7,\n",
    "                      day=1)\n",
    "    age = int((photo_date - dob).days // 365)\n",
    "    return age\n",
    "\n",
    "df['age'] = df.apply(lambda row : calculate_age_in_year(row['dob'], row['photo_date']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df.apply(lambda row: calculate_age_in_year(row['dob'], row['photo_date']), axis=1)\n",
    "df = df[(df['age'] <= 100) & (df['age'] > 0)]\n",
    "bins_age = [0, 20, 30, 40, 50, 60, 100]\n",
    "df.loc[:, 'age_cat'] = pd.cut(df['age'], bins_age, labels=False, right=False)\n",
    "# pd.cut(df['age'], [0, 20, 25, 32, 38, 45, 60], labels=False, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val, test : 0.7, 0.2, 0.1\n",
    "random_state = 42\n",
    "celeb_id_train, celeb_id_val = train_test_split(df['celeb_id'].unique(), test_size=0.2,   random_state=random_state)\n",
    "celeb_id_train, celeb_id_test = train_test_split(celeb_id_train,         test_size=0.125, random_state=random_state)\n",
    "df.loc[df['celeb_id'].isin(celeb_id_train), 'set'] = 'train'\n",
    "df.loc[df['celeb_id'].isin(celeb_id_val),   'set'] = 'val'\n",
    "df.loc[df['celeb_id'].isin(celeb_id_test),  'set'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['dob', 'photo_date', 'celeb_id', 'age'], axis=1, inplace=True)\n",
    "num_cat_age = df['age_cat'].nunique()\n",
    "df = df[df['set'] == 'train']\n",
    "# df = df.head(20000)\n",
    "print(num_cat_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ainsi chargé les images ayant les labels qui nous intéressent dans un dataframe panda, qui contient :\n",
    "- le nom des images : image_names\n",
    "- le genre : gender_classes (0 ou 1)\n",
    "- La catégorie d'age (de 0 a 6 selon le découpage 0-20, 20-30, 30-40, 40-50, 50-60, 60-100, 100+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "def preprocessing_img(img):  \n",
    "    return(img.astype(float)/255.0)\n",
    "    #return(2*(img.astype(float) - 127.5)/255.0)\n",
    "\n",
    "def _imread(image_name):\n",
    "#     return plt.imread(image_name)\n",
    "    return cv2.imread(image_name)\n",
    "\n",
    "def _imresize(image_array, size):\n",
    "    return cv2.resize(image_array, dsize=size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER\n",
    "def build_encoder(input_dim, output_dim, conv_filters, conv_kernel_size, \n",
    "                  conv_strides):\n",
    "  \n",
    "  # Clear tensorflow session to reset layer index numbers to 0 for LeakyRelu, \n",
    "  # BatchNormalization and Dropout.\n",
    "  # Otherwise, the names of above mentioned layers in the model \n",
    "  # would be inconsistent\n",
    "  global K\n",
    "  K.clear_session()\n",
    "  \n",
    "  # Number of Conv layers\n",
    "  n_layers = len(conv_filters)\n",
    "\n",
    "  # Define model input\n",
    "  encoder_input = Input(shape = input_dim, name = 'encoder_input')\n",
    "  x = encoder_input\n",
    "\n",
    "  # Add convolutional layers\n",
    "  for i in range(n_layers):\n",
    "      x = Conv2D(filters = conv_filters[i], \n",
    "                  kernel_size = conv_kernel_size[i],\n",
    "                  strides = conv_strides[i], \n",
    "                  padding = 'same',\n",
    "                  name = 'encoder_conv_' + str(i)\n",
    "                  )(x)\n",
    "\n",
    "      x = LeakyReLU()(x)\n",
    "    \n",
    "  # Required for reshaping latent vector while building Decoder\n",
    "  shape_before_flattening = K.int_shape(x)[1:] \n",
    "  \n",
    "  x = Flatten()(x)\n",
    "\n",
    "  # Define model output\n",
    "  encoder_output = Dense(output_dim, name = 'encoder_output')(x)\n",
    "\n",
    "  return encoder_input, encoder_output, shape_before_flattening, Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input, encoder_output,  shape_before_flattening, encoder  = build_encoder(input_dim = INPUT_DIM,\n",
    "                                    output_dim = Z_DIM, \n",
    "                                    conv_filters = [32, 64, 64, 64],\n",
    "                                    conv_kernel_size = [3,3,3,3],\n",
    "                                    conv_strides = [2,2,2,2])\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "def build_decoder(input_dim, shape_before_flattening, conv_filters, conv_kernel_size, \n",
    "                  conv_strides):\n",
    "\n",
    "  # Number of Conv layers\n",
    "  n_layers = len(conv_filters)\n",
    "\n",
    "  # Define model input\n",
    "  decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n",
    "\n",
    "  # To get an exact mirror image of the encoder\n",
    "  x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "  x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "  # Add convolutional layers\n",
    "  for i in range(n_layers):\n",
    "      x = Conv2DTranspose(filters = conv_filters[i], \n",
    "                  kernel_size = conv_kernel_size[i],\n",
    "                  strides = conv_strides[i], \n",
    "                  padding = 'same',\n",
    "                  name = 'decoder_conv_' + str(i)\n",
    "                  )(x)\n",
    "      \n",
    "      # Adding a sigmoid layer at the end to restrict the outputs \n",
    "      # between 0 and 1\n",
    "      if i < n_layers - 1:\n",
    "        x = LeakyReLU()(x)\n",
    "      else:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "  # Define model output\n",
    "  decoder_output = x\n",
    "\n",
    "  return decoder_input, decoder_output, Model(decoder_input, decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input, decoder_output, decoder = build_decoder(input_dim = Z_DIM,\n",
    "                                        shape_before_flattening = shape_before_flattening,\n",
    "                                        conv_filters = [64,64,32,3],\n",
    "                                        conv_kernel_size = [3,3,3,3],\n",
    "                                        conv_strides = [2,2,2,2]\n",
    "                                        )\n",
    "\n",
    "decoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input to the model will be the image fed to the encoder.\n",
    "simple_autoencoder_input = encoder_input\n",
    "\n",
    "# The output will be the output of the decoder. The term - decoder(encoder_output) \n",
    "# combines the model by passing the encoder output to the input of the decoder.\n",
    "simple_autoencoder_output = decoder(encoder_output)\n",
    "\n",
    "# Input to the combined model will be the input to the encoder.\n",
    "# Output of the combined model will be the output of the decoder.\n",
    "simple_autoencoder = Model(simple_autoencoder_input, simple_autoencoder_output)\n",
    "\n",
    "simple_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "optimizer = Adam(lr = LEARNING_RATE)\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "simple_autoencoder.compile(optimizer=optimizer, loss = r_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement de l'autoencodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "patience = 5 #nb epoch without improvement before stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks for training\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# model callbacks\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/2), verbose=1)\n",
    "model_names = '{epoch:02d}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, model_names),\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Décommenter le script suivant pour lancer l'entrainement de l'autoencodeur. Si des poids sont déjà existants dans le dossier WEIGHTS_FOLDER, on peut juste les charger dans le script d'après."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# simple_autoencoder.fit_generator(data_flow_train, \n",
    "#                                  shuffle=True, \n",
    "#                                  epochs = N_EPOCHS, \n",
    "#                                  initial_epoch = 0, \n",
    "#                                  validation_data = data_flow_val,\n",
    "#                                  steps_per_epoch= NUM_IMAGES / BATCH_SIZE,\n",
    "#                                  callbacks=[model_checkpoint, early_stop, reduce_lr])\n",
    "\n",
    "# encoder.save_weights('encoder_weights.h5')\n",
    "# decoder.save_weights('decoder_weights.h5')\n",
    "# simple_autoencoder.save_weights('autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights(os.path.join(WEIGHTS_FOLDER,\"encoder_weights.h5\"))\n",
    "decoder.load_weights(os.path.join(WEIGHTS_FOLDER,\"decoder_weights.h5\"))\n",
    "simple_autoencoder.load_weights(os.path.join(WEIGHTS_FOLDER,\"autoencoder_weights.hdf5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage d'images en entree et sortie de l'autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(data_flow_train)\n",
    "\n",
    "example_batch = example_batch[0]\n",
    "example_images = example_batch[:10]\n",
    "\n",
    "example_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(images=None):\n",
    "  \n",
    "  if images is None:\n",
    "    example_batch = next(data_flow)\n",
    "    example_batch = example_batch[0]\n",
    "    images = example_batch[:10]\n",
    "\n",
    "  n_to_show = images.shape[0]\n",
    "\n",
    "  reconst_images = simple_autoencoder.predict(images)\n",
    "\n",
    "  fig = plt.figure(figsize=(15, 3))\n",
    "  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "  for i in range(n_to_show):\n",
    "      img = images[i].squeeze()\n",
    "      sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "      sub.axis('off')        \n",
    "      sub.imshow(img)\n",
    "\n",
    "  for i in range(n_to_show):\n",
    "      img = reconst_images[i].squeeze()\n",
    "      sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "      sub.axis('off')\n",
    "      sub.imshow(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(example_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Network params (inputs/outputs)\n",
    "\"\"\"\n",
    "image_shape = (64, 64, 3)  # input image size\n",
    "input_shape = image_shape\n",
    "n_y = num_cat_age + 2  # labels dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator():\n",
    "\n",
    "        X = []\n",
    "        y_age = []\n",
    "        y_gender = []\n",
    "        idx_list=[]\n",
    "        for idx, row in df.iterrows():\n",
    "            # images\n",
    "            image_path = os.path.join(images_path, row['image_names'])\n",
    "            image_array = _imread(image_path)\n",
    "            image_array = _imresize(image_array, image_shape[:2])\n",
    "            image_array = preprocessing_img(image_array)\n",
    "            X.append(image_array)\n",
    "                           \n",
    "            # labels\n",
    "            y_gender.append(row['gender_classes'])\n",
    "            y_age.append(row['age_cat'])\n",
    "            idx_list.append(idx)\n",
    "            \n",
    "            \n",
    "            if len(X) == BATCH_SIZE :     \n",
    "                    # images\n",
    "                    X = np.asarray(X)\n",
    "                    \n",
    "                    # labels\n",
    "                    y_age = to_categorical(y_age, num_classes=num_cat_age)\n",
    "                    y_gender = np.array(y_gender).reshape(-1, 1)\n",
    "                    y_gender = to_categorical(y_gender, num_classes=2)\n",
    "                    Y = np.hstack((y_age,y_gender))\n",
    "                    \n",
    "                    yield X, Y, idx_list\n",
    "                    X = []\n",
    "                    y_age = []\n",
    "                    y_gender = []\n",
    "                    idx_list= []\n",
    "                    \n",
    "                \n",
    "        if len(X) > 0 : \n",
    "                # images\n",
    "                X = np.asarray(X)\n",
    "\n",
    "                # labels\n",
    "                y_age = to_categorical(y_age, num_classes=num_cat_age)\n",
    "                y_gender = np.array(y_gender).reshape(-1, 1)\n",
    "                y_gender = to_categorical(y_gender, num_classes=2)\n",
    "                Y = np.hstack((y_age,y_gender))\n",
    "\n",
    "                yield X, Y, idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions sur toutes les images avec label et enregistrement du vecteur obtenu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va calculer pour chacune des images du dataset le vecteur en sortie de l'encodeur, pour pouvoir ensuite calculer le vecteur moyen par classe, qui va nous servir ensuite pour la modification des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_encoder_output_vector():\n",
    "    ##Creation du numpy array\n",
    "    global encoder_output_vector\n",
    "    \n",
    "    img_gen = image_generator()\n",
    "\n",
    "    for (images_batch, y_batch, idx) in img_gen :\n",
    "        print(images_batch)\n",
    "        #print(test.shape)  #(512, 64)\n",
    "        print(encoder_output_vector[idx,:].shape)\n",
    "        encoder_output_vector[idx,:]=encoder.predict_on_batch([images_batch])\n",
    "        print(encoder_output_vector[idx,:])\n",
    "        #encoder_output_vector=np.concatenate((encoder_output_vector, encoder.predict_on_batch([images_batch])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du numpy array contenant les vecteurs des outputs de l'encoder\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "if path.exists(\"array/encoder_vector.npy\"):\n",
    "    encoder_output_vector = np.load('array/encoder_vector.npy', allow_pickle=True)\n",
    "    \n",
    "else :\n",
    "    from tempfile import TemporaryFile\n",
    "    encoder_vector = TemporaryFile()\n",
    "\n",
    "    encoder_output_vector= np.empty((df.shape[0],Z_DIM))\n",
    "    calculate_encoder_output_vector()\n",
    "    \n",
    "    np.save('array/encoder_vector.npy', encoder_output_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du vecteur moyen par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(vector):\n",
    "    len_i=len(vector)\n",
    "    len_j=len(vector[0])\n",
    "    return([sum(vector[i][j] for i in range(len_i))/len_i for j in range(len_j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender class0\n",
    "\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "\n",
    "vector_gender_class0 = []\n",
    "\n",
    "test = df.loc[df['gender_classes'] == 0.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['gender_classes'] == 0.0].iterrows() :\n",
    "    vector_gender_class0.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_gender_class0)\n",
    "len_j=len(vector_gender_class0[0])\n",
    "\n",
    "mean_vector_gender_class0 = [sum(vector_gender_class0[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_gender_class0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender class1\n",
    "\n",
    "vector_gender_class1 = []\n",
    "\n",
    "test = df.loc[df['gender_classes'] == 1.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['gender_classes'] == 1.0].iterrows() :\n",
    "    vector_gender_class1.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_gender_class1)\n",
    "len_j=len(vector_gender_class1[0])\n",
    "\n",
    "mean_vector_gender_class1 = [sum(vector_gender_class1[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_gender_class1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class0\n",
    "\n",
    "vector_age_class0 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 0.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 0.0].iterrows() :\n",
    "    vector_age_class0.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class0)\n",
    "len_j=len(vector_age_class0[0])\n",
    "\n",
    "mean_vector_age_class0 = [sum(vector_age_class0[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class1\n",
    "\n",
    "vector_age_class1 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 1.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 1.0].iterrows() :\n",
    "    vector_age_class1.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class1)\n",
    "len_j=len(vector_age_class1[0])\n",
    "\n",
    "mean_vector_age_class1 = [sum(vector_age_class1[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class2\n",
    "\n",
    "vector_age_class2 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 2.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 2.0].iterrows() :\n",
    "    vector_age_class2.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class2)\n",
    "len_j=len(vector_age_class2[0])\n",
    "\n",
    "mean_vector_age_class2 = [sum(vector_age_class2[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class3\n",
    "\n",
    "vector_age_class3 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 3.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 3.0].iterrows() :\n",
    "    vector_age_class3.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class3)\n",
    "len_j=len(vector_age_class3[0])\n",
    "\n",
    "mean_vector_age_class3 = [sum(vector_age_class3[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class4\n",
    "\n",
    "vector_age_class4 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 4.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 4.0].iterrows() :\n",
    "    vector_age_class4.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class4)\n",
    "len_j=len(vector_age_class4[0])\n",
    "\n",
    "mean_vector_age_class4 = [sum(vector_age_class4[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class4).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age class5\n",
    "\n",
    "vector_age_class5 = []\n",
    "\n",
    "test = df.loc[df['age_cat'] == 5.0]\n",
    "print(test.shape)\n",
    "\n",
    "for idx, row in df.loc[df['age_cat'] == 5.0].iterrows() :\n",
    "    vector_age_class5.append(encoder_output_vector[idx])\n",
    "    \n",
    "len_i=len(vector_age_class5)\n",
    "len_j=len(vector_age_class5[0])\n",
    "\n",
    "mean_vector_age_class5 = [sum(vector_age_class5[i][j] for i in range(len_i))/len_i for j in range(len_j)]\n",
    "print(np.array(mean_vector_age_class5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector_gender_class0=np.array(mean_vector_gender_class0)\n",
    "mean_vector_gender_class1=np.array(mean_vector_gender_class1)\n",
    "\n",
    "mean_vector_age_class0=np.array(mean_vector_age_class0)\n",
    "mean_vector_age_class1=np.array(mean_vector_age_class1)\n",
    "mean_vector_age_class2=np.array(mean_vector_age_class2)\n",
    "mean_vector_age_class3=np.array(mean_vector_age_class3)\n",
    "mean_vector_age_class4=np.array(mean_vector_age_class4)\n",
    "mean_vector_age_class5=np.array(mean_vector_age_class5)\n",
    "\n",
    "np.save('array/mean_vector_gender_class0.npy', mean_vector_gender_class0)\n",
    "np.save('array/mean_vector_gender_class1.npy', mean_vector_gender_class1)\n",
    "\n",
    "np.save('array/mean_vector_age_class0.npy', mean_vector_age_class0)\n",
    "np.save('array/mean_vector_age_class1.npy', mean_vector_age_class1)\n",
    "np.save('array/mean_vector_age_class2.npy', mean_vector_age_class2)\n",
    "np.save('array/mean_vector_age_class3.npy', mean_vector_age_class3)\n",
    "np.save('array/mean_vector_age_class4.npy', mean_vector_age_class4)\n",
    "np.save('array/mean_vector_age_class5.npy', mean_vector_age_class5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les calculs à partir des vecteurs moyens sont ensuite effectués dans le script main_ae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Debug code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(data_flow_train)\n",
    "example_batch = example_batch[0]\n",
    "\n",
    "example_image = example_batch[3:4]\n",
    "\n",
    "print(example_image.shape)\n",
    "\n",
    "img_encoded = encoder.predict(example_image)\n",
    "img_decoded = decoder.predict(np.reshape(mean_vector_age_class5, (1,Z_DIM))+(img_encoded))\n",
    "# img_decoded = decoder.predict(img_encoded)\n",
    "\n",
    "\n",
    "print(\"mean :\", np.mean(img_encoded))\n",
    "vector_modified = 2*mean_vector_age_class5+(img_encoded)\n",
    "print(\"mean modified : \", np.mean(vector_modified))\n",
    "\n",
    "mean = np.mean(img_encoded)\n",
    "mean_modif = np.mean(vector_modified)\n",
    "\n",
    "vector_modified[:] = [i+(mean - mean_modif) for i in vector_modified]\n",
    "\n",
    "print(vector_modified.shape)\n",
    "    \n",
    "print(\"mean modified : \", np.mean(vector_modified))\n",
    "\n",
    "img_decoded_modified = decoder.predict(vector_modified)\n",
    "plt.figure()\n",
    "plt.imshow(img_decoded_modified[0])\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "print(img_decoded.shape)\n",
    "matplotlib.image.imsave('name.jpg', img_decoded[0])\n",
    "\n",
    "##Tentative de retirer la dernière coordonnée pour le .jpg\n",
    "img_decoded = matplotlib.pyplot.imread('name.jpg', format=None)\n",
    "img_decoded = img_decoded[:, :, :3]\n",
    "######\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(example_image[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_decoded)\n",
    "\n",
    "\n",
    "# ##############################################\n",
    "# #Reshaping pour correspondre à ce qui est voulu\n",
    "# test = np.reshape(encoder_output_vector[10], (1,Z_DIM))\n",
    "\n",
    "# img_decoded = decoder.predict(test)\n",
    "# plt.figure()\n",
    "# plt.imshow(img_decoded[0])\n",
    "# matplotlib.image.imsave('test.jpg', img_decoded[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Reconstruction en femme\n",
    "# test = np.reshape(mean_vector_gender_class0, (1,Z_DIM))\n",
    "\n",
    "# img_decoded = decoder.predict(test)     #vecteur moyen\n",
    "# img_decoded = decoder.predict(np.reshape(mean_vector_gender_class0, (1,Z_DIM))+np.reshape(encoder_output_vector[10], (1,Z_DIM)))     #Image + vecteur moyen\n",
    "\n",
    "# print(np.array(img_decoded[0]).shape)\n",
    "# matplotlib.image.imsave('test2.jpg', img_decoded[0])\n",
    "# #img_decoded = decoder.predict(test)\n",
    "# plt.figure()\n",
    "# plt.imshow(img_decoded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes\n",
    "\n",
    "img_gen = image_generator()\n",
    "\n",
    "for (images_batch, y_batch, idx) in img_gen :\n",
    "    #print(test.shape)  #(512, 64)\n",
    "    test = encoder.predict_on_batch([images_batch])\n",
    "    test=test[0]\n",
    "    print(test.shape)\n",
    "    test2 = decoder.predict([[test]], batch_size=None)\n",
    "    print(test2.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
